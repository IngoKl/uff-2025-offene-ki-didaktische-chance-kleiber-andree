{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cb532e-b582-47c4-b3b2-90e2b6c6d6b3",
   "metadata": {},
   "source": [
    "# U:FF 2025 Tier Prediction (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c16905-3de5-4a70-8a4f-043c86d1d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4dd56-0409-4d02-bf91-c503bf5026f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_grid(image_path, rows, cols, label):\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    tile_width = width // cols\n",
    "    tile_height = height // rows\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            box = (j * tile_width, i * tile_height, (j + 1) * tile_width, (i + 1) * tile_height)\n",
    "            tile = img.crop(box)\n",
    "            tile = tile.resize((32, 32))  # Resize for uniformity\n",
    "            images.append(tile)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2899e-56bf-43d4-9116-e4360749ef08",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53b0a9-cba8-4194-8f9d-8b694d6182c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(images):\n",
    "    X = [np.array(img.convert('L')).flatten() / 255.0 for img in images]  # grayscale + normalization\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ec11b-1255-4111-af4c-ee81ad64faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_specs = [\n",
    "    (\"tiere/uff-tiere-lieb-1.png\", 6, 6, 0),  # label 0 = lieb\n",
    "    (\"tiere/uff tiere-lieb-2.png\", 6, 6, 0),\n",
    "    (\"tiere/uff-tiere-böse-1.png\", 6, 6, 1),  # label 1 = böse\n",
    "    (\"tiere/uff-tiere-böse-2.png\", 6, 6, 1)\n",
    "]\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for path, rows, cols, label in sheet_specs:\n",
    "    imgs, labels = split_image_grid(path, rows, cols, label)\n",
    "    all_images.extend(imgs)\n",
    "    all_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63831fb4-4fe1-428b-a6c7-b13eefbdfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d739b09-f8b6-41fc-8752-58a0e194da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepare_data(all_images)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6db40-4f8b-452a-bf6b-d3775d027d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()  # for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343934a-9f1d-451a-b31b-6d6d0b05bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(X_train.shape[1])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    predicted_classes = (predictions > 0.5).float()\n",
    "    accuracy = (predicted_classes == y_test_tensor).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78761f-36db-4935-ba26-e56d643d3e54",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f54de-69e7-4437-ac14-7315c04d88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = split_image_grid(\"tiere/uff-tiere-gemischt.png\", 6, 6, 2)\n",
    "X_mixed = prepare_data(imgs)\n",
    "\n",
    "X_mixed_tensor = torch.tensor(X_mixed, dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_probs = model(X_mixed_tensor)\n",
    "    pred_labels = (pred_probs > 0.5).float()\n",
    "\n",
    "predictions = pred_labels.numpy().astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d08be-e835-4dc8-87b6-9291a60cceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc893d-0602-4026-9aa9-91bf3238a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b8e9e-ef54-45cd-bf2d-38211d5aca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predictions_on_tiles(tiles, predictions):\n",
    "    labeled_tiles = []\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for img, pred in zip(tiles, predictions):\n",
    "        label = \"Lieb\" if pred == 0 else \"Boese\"\n",
    "\n",
    "        img_copy = img.convert(\"RGBA\")\n",
    "        txt_overlay = Image.new(\"RGBA\", img_copy.size, (255, 255, 255, 0))\n",
    "        draw = ImageDraw.Draw(txt_overlay)\n",
    "\n",
    "        bbox = draw.textbbox((0, 0), label, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "        x = (img_copy.width - text_width) // 2\n",
    "        y = (img_copy.height - text_height) // 2\n",
    "\n",
    "        padding = 4\n",
    "        background_box = [\n",
    "            x - padding,\n",
    "            y - padding,\n",
    "            x + text_width + padding,\n",
    "            y + text_height + padding\n",
    "        ]\n",
    "        draw.rectangle(background_box, fill=(255, 255, 255, 180))\n",
    "\n",
    "        draw.text((x, y), label, fill=\"black\", font=font)\n",
    "\n",
    "        combined = Image.alpha_composite(img_copy, txt_overlay).convert(\"RGB\")\n",
    "        labeled_tiles.append(combined)\n",
    "\n",
    "    return labeled_tiles\n",
    "\n",
    "def save_image_grid(images, rows, cols, output_path):\n",
    "    w, h = images[0].size\n",
    "    grid_img = Image.new(\"RGB\", (cols * w, rows * h), \"white\")\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        grid_img.paste(img, (col * w, row * h))\n",
    "\n",
    "    grid_img.save(output_path)\n",
    "    print(f\"Saved prediction grid to: {output_path}\")\n",
    "\n",
    "labeled = draw_predictions_on_tiles(imgs, predictions)\n",
    "save_image_grid(labeled, 6, 6, \"predicted_grid_nn.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
